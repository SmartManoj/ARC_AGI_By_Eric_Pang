{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import jax\n",
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.serialization import from_bytes\n",
    "import json\n",
    "\n",
    "from src.models.lpn import LPN\n",
    "from src.evaluator import Evaluator\n",
    "from src.models.transformer import EncoderTransformer, DecoderTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARNING: first download the desired checkpoint folder using e.g. the `load_checkpoint` notebook. Then load it like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_checkpoint_path = \"/kaggle/input/absurd-river-1068-checkpointv2/jax/default/1/absurd-river-1068--checkpoint:v2\"\n",
    "cfg = omegaconf.OmegaConf.load(os.path.join(local_checkpoint_path, \"config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderTransformer(hydra.utils.instantiate(cfg.encoder_transformer))\n",
    "decoder = DecoderTransformer(hydra.utils.instantiate(cfg.decoder_transformer))\n",
    "lpn = LPN(encoder=encoder, decoder=decoder)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "grids = jax.random.randint(\n",
    "    key, (1, 3, decoder.config.max_rows, decoder.config.max_cols, 2), minval=0, maxval=decoder.config.vocab_size,\n",
    ")\n",
    "shapes = jax.random.randint(\n",
    "    key, (1, 3, 2, 2), minval=1, maxval=min(decoder.config.max_rows, decoder.config.max_cols) + 1,\n",
    ")\n",
    "variables = lpn.init(key, grids, shapes, dropout_eval=False, prior_kl_coeff=0.0, pairwise_kl_coeff=0.0, mode=\"mean\")\n",
    "learning_rate, linear_warmup_steps = 0, 0\n",
    "linear_warmup_scheduler = optax.warmup_exponential_decay_schedule(\n",
    "    init_value=learning_rate / (linear_warmup_steps + 1),\n",
    "    peak_value=learning_rate,\n",
    "    warmup_steps=linear_warmup_steps,\n",
    "    transition_steps=1,\n",
    "    end_value=learning_rate,\n",
    "    decay_rate=1.0,\n",
    ")\n",
    "optimizer = optax.chain(optax.clip_by_global_norm(1.0), optax.adamw(linear_warmup_scheduler))\n",
    "optimizer = optax.MultiSteps(optimizer, every_k_schedule=1)\n",
    "train_state = TrainState.create(apply_fn=lpn.apply, tx=optimizer, params=variables[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(local_checkpoint_path, \"state.msgpack\"), \"rb\") as data_file:\n",
    "    byte_data = data_file.read()\n",
    "loaded_state = from_bytes(train_state, byte_data)\n",
    "loaded_state = jax.device_put_replicated(loaded_state, jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(\n",
    "    lpn,\n",
    "    inference_mode=\"gradient_ascent\",\n",
    "    inference_mode_kwargs={\n",
    "        \"num_steps\": 200,\n",
    "        \"lr\": 1.0,\n",
    "        \"lr_schedule\": True,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"optimizer_kwargs\": {\"b2\": 0.9},\n",
    "        \"accumulate_gradients_decoder_pairs\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "with open(\"/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\", \"r\") as f:\n",
    "    challenges = json.load(f)\n",
    "generations = evaluator.json_submission(challenges, loaded_state.params, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission.json\", \"w\") as f:\n",
    "    json.dump(generations, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
